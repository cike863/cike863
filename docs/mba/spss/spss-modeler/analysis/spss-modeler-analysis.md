# 7：描述性统计分析



## 7.1 描述性统计分析概述

### 7.1.1 数据的集中趋势指标

数据的集中趋势是描述性统计分析中最具有代表的一组指标，反映了一组数据的“普遍水平”。居住于数据的集中趋势，能够让用户更好了解数据的中心。一般来说，数据的其中趋势波爱护平均数、中位数、众数

1. 平均数

   如果说数据的集中趋势是描述性统计分析中最具有代表性的一组指标，那么平均数则是集中趋势中最常用的指标，平均数也分为多类，一般使用算数平均数

2. 中位数

   要获得数据的中心，出了使用求和取平均外，为一种思路就是对数据进行排序后取中间的书作为代表，这个数据就是中位数

3. 众数

   我们把一组数据中出现频率最多的数据称为众数。由于值考虑到频率信息，因此在一组连续型变量数据中可能不存在众数或存在多个众数。一般来说，由于众数能够反映的统计特征不是十分充分，因此我们更常在分类型变量数据中使用众数

4. 中位数与平均数的比较

   平均数和中华苏是常用于数据集中趋势的分析，一般来说，使用平均数似乎更能符合人们的直觉思维，但是对于存在极端值的数据来说，平均数可能存在明细的偏差

   另外平均数的偏差是由于极端值所带来的影响，因此另一种思路是使用结尾均值。

### 7.1.2 数据的离散趋势指标

数据的离散趋势包含极差、分位数与四位分差、方差与标准差

1. 极差

   一组数据中最大值与最小值的差异称为极差，只管反应了一组数据的最大波动范围，但由于极差只考虑的最大值和最小值，而没有考虑内部的波动情况，故一般不会被直接使用

2. 分位数与四位分差

   分位数是一种对数据按照大小排序后按照顺序位置划分的统计量，一般最常使用是四分位数以及百分位数。要计算四分位数，首先需要对数据进行排序，之后按照25%，50%，75%的位置确定对应的分位数。

   ​	第一四分位数 Q1：下四分位数，有25%的值小于该值

   ​	第二四分位数Q2：中位数，数据的中心位置

   ​	第三四分位数Q3：上四分位数，有25%的值大于该值

   为了考察数据内部的波动情况，可以使用四分位差Qd=Q3-Q1，四分位差不会受到数据极端值的波动，他反应了数据中间位置的波动情况。

3. 方差与标准差

   一般来说，使用离差来衡量每个样本聚类中心远近，因此如果要反映整体数据的波动情况，则可以在帮帮离差的基础上进行汇总，使用方差
   $$
   S^2=\frac{\sum_{i=1}^{n}{(x_i-\overline{x})^2}}{y}
   $$
   进一步地，考虑到方差的量纲相对于原始数据的ingt，异常一般更常使用标准差，标准层就是方法的开方

   
   $$
   S=\sqrt{{\sum_{i=1}^{n}{(x_i-\overline{x})^2}}{y}}
   $$

4. 标准误差

   标准误差常用于衡量估算值与真实值时间的偏差，一般可以使用统计量以及标准差误差来计算参数的置信区间。标准误差的计算公式为
   $$
   SE=\sqrt{\frac{S^2}{n}}=\frac{S}{\sqrt{n}}
   $$

### 7.1.3 数据的分布形态指标

集中趋势和离散趋势是对数据进行描述性分析的两个重要特征，在此基础上，还可以借助数据的分布特征来进一步认识数据，数据的分布形态一般包含偏度以及峰度，其中偏度是描述统计数据是否对称的统计量，二峰度是描述数据的陡峭平缓的统计量



1. 偏度

   是数据对称情况的统计量，一般来说，数据分布形态的统计量都是对比型的统计量

   对于随机变量X，若E(X^k),k=1，2.....存在，则称他为随机变量X的k阶原点矩；若E[(X-E(X^k)]^k,k=1，2.....存在，则称他为随机变量X的k阶原点矩；则称他为随机变量X的k阶中心距。一般，使用距来描述随机变量的特性，随机变量的数据期望就是一阶原点矩E(X)，方差则是二阶中心距E[(X-E(X^2)]^2，偏度是三阶标准中心距，峰度则是四阶标准中心距。

   

   偏度计算公式为
   $$
   SK=\frac{n\sum_{i=1}^{n}{(x_i-\overline{x})^3}}{(n-1)(n-2)s^3}
   $$
   当数据对称分布的情况下，SK=0，正态分布的偏度为0，当SK>0时，则分布为正偏（右偏），即分布有一条长尾在右；当SK<0，则分布为负偏（右偏），即分布有一条长尾在左。一般来说，偏度的绝对值越大，说明分布的偏移程度越严重

   ​	从图形上看，偏度方向不是看“峰”的位置，而是看“尾”的位置，当SK>0时，分布右偏，长尾在右，高作在左，这似乎与一般认知不太一致。当其时我们可以知道偏度实际上是三阶段标准中心距，而一个数据距离“中心”越远，对中心距的计算影响越大。因而当数据长尾在右，即有更多正偏的离群值，SK>0

2. 峰度

   是数据分布陡峭平缓情况的统计量，同样，峰度也是熟悉对比型的统计量，一般使用峰度来衡量该组数据的分布形态相对于正态分布的偏离程度。

   峰度计算公式为
   $$
   K_u=\frac{n(n+1)\sum_{i=1}^{n}{(x_i-\overline{x})^4}}{(n-1)(n-2)(n-3)s^4}-\frac{3(n-1)^2}{(n-2)(n-3)}
   $$
   值得注意的是，峰度的对比标准是对比于正态分布的偏离程度，因此正态分布的峰度系数等于0，当Ku>0时，分布相比于正态分布更加陡峭或尾部更厚（如指数分布的峰度系数为6），当Ku<0，分布相比于正态分布更加平缓活尾部更薄（如均匀分布的峰度系数为-1.2）

3. 利用偏度与峰度进行数据正态性校验

   记录偏度和峰度反映的是相比于正态分布的偏离程度，那么当某个正态分布的偏度或峰度偏离程度超过一定的阈值时，就可以认为该分布不服从正态分布

   一般的校验方法为，当偏度系数或峰度系数与标准差的比率小于-2或大于2，则可以拒绝认为该数据服从正态分布

   偏度系数标准差的计算公式为
   $$
   S_{SK}=\sqrt\frac{6(n-1)}{(n+1)(n-2)(n+3)}
   $$




​		峰度度系数标准差的计算公式为
$$
S_{K_u}=\sqrt\frac{4(n^2-1)*S_{SK}^2}{(n-3)(n+5)}
$$
​		从上述公式可以看出，偏度以及峰度的标准差只与样本数量有关

## 7.2 数据审核

​	“数据审核”节点可以看做是一个综合性的报告输出节点，能够针对已经准备好的数据一键生成一份完整“数据报告”。在报告中，将生成对每个数据字段的“审核分析”和“质量分析”，在审核分析中，将输出字段汇总统计量、直方图、和分布图的分析，而在质量分析中，将输出字段完整度、离群值和缺失值的分析。

![image-20230110084413861](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110084413861.png)

- 设置
  - 缺省：根据默认选项设定需要分析的字段
    - 如果没有 “类型”节点，“数据审核”节点将把所有字段纳入分析
    - 如果前面已经设置了“类型”节点，则会把角色设置为“无”的字段排除在外，其他所有角色的字段都将纳入分析，同时“数据审核”节点，将会把角色设置为“目标”的字段作为交叠字段。如果设置了多个交叠字段，则不指定“交叠字段”
  - 使用定制字段：手动指定需要分析的字段
  - 交叠字段：节点将更加交叠字段的类型输出更多的比较分析结果
  - 显示：用户指定数据审核报告的内容，包括“图形”、“基本统计量”、“高级统计量”
    - 图形：将根据字段类型及交叠字段类型生成对应的图形结果
    - 基本统计量：包括最小值、最大值、平均值、标注差、偏度、唯一值及有效值
    - 高级统计量：包含合计、范围（极差）、平均值标准差、偏度系数标准差、峰度、峰度系数标准差
  - 计算中位数和众数

- 质量

  ![image-20230110085223711](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110085223711.png)

  - 缺失值：计算每个字段的有效记录，具体包含有效记录数及无效记录数
    - 具有有效记录计数：计算米格字段有效记录数量（非空）
    - 分解具有无效值的记录计数：对于无效值的记录进行分类统计，具体类别包括空值、字符串空值、空白及空白值
  - 离群值和极值：统计离群值和极值的记录，包含两种离群值和极值的检查方法
    - 平均值的标准差：以平均值为中心，超过3个标准差范围以外的记录定义为离群值，超过5个标准差范围记录以外的定义为极值
    - 输入四分位距的上/下四分位数范围：以下四分位数Q1及上四分位数Q3为限、四分位距IQR为标准计算，下离群值=Q1-1.5*IQR，上离群值=Q3+1.5IQR，对应的极值则为3倍的IQR

- 数据分析报过结果

  ![image-20230110090325763](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110090325763.png)

  通过修改字段增加交叠字段

  ![image-20230110092407460](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110092407460.png)

-  数据质量分析

  ![image-20230110092644055](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110092644055.png)

## 7.3 缺失值定义、检查和处理

### 7.3.1 缺失值定义和检查

![image-20230110093125324](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110093125324.png)

如上图发现Age 的值范围为[-1.0,77.0]

![image-20230110093609506](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110093609506.png)

通过“数据审核“节点，发现Age 字段没有报告存在缺失值。

可以在“类型”节点中，对缺失值进行定义和检查。

![image-20230110094015849](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110094015849.png)

- 检查

  - 无：默认操作，即不对字段的值进行检查
  - 无效：将超出限制的值更改为系统空值（null）
  - 强制：若字段已实例化，将在该字段中把超过限制的值更改为符合字段测量级别的合法值。不同测量级别的转换有以下3种
    - 标志：将真值和假值以外的值转换为假值
    - 集合：将未知值转换为集合值的第一个成员
    - 数值：大于定义域范围上限的值将转换为最大值，小于定义域范围下限的值将转换为最小值，空值将转换为范围的中间值，即(最大值+最小值)/2
  - 丢弃：如果在检查中发现非法值，将丢弃该记录
  - 警告：如果在检查中发现非法值，将在右下角“流消息”对话框中显示告警消息
  - 中止：如果在检查中发现非法值，将终止运行，并提示错误

- 缺失

  - 开(*)：指示已为该字段进行缺失值处理

  - 关：指示没有为该字段进行缺失值处理

  - 指定：选择“指定”，将弹出操作对话框，为字段进行针对性的缺失值指定处理

    ![image-20230110102148589](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110102148589.png)

  - “值”选项：可以定义该字段值的有效范围

  - 检查值：可以在此处定义检查操作

  - 定义空白：与值选项的定义有效范围不同，定义空白是定义对空白值的识别

    重新运行数据审核

    ![image-20230110103256766](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110103256766.png)



### 7.3.2 缺失值自动化处理

- 空字符串的处理

  一般把缺失值选手出来进行丢弃或者填充

  ![image-20230110103514212](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110103514212.png)

  ![image-20230110103538137](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110103538137.png)

  - 查询无效值
    - 所有字段：对质量报告中的所有字段查询缺失值
    - 表格中所选字段：在表格中客诉选择多个字段，选择此字段将仅在选择的字段中查询缺失值
    - 在质量百分比高于%的字段：只查询数据质量高于指定阈值的字段

  - 如果在以下位置发现无效值，则认为无效

    - 以上任何字段：只要在上述指定的字段范围中发现无效值，即任务记录无效 即or
    - 以上所有字段：只有在上述指定的字段中每个字段都发现无效值，即认为记录无效，即and

    设置完后，运行设置。将会生成“选择”节点

    ![image-20230110104416941](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110104416941.png)

    

- 空白值的处理

  对于数值型空白值，一般可以使用缺失值插补的方法填充

  ![image-20230110104601346](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110104601346.png)

  ![image-20230110104650443](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110104650443.png)

  - 固定：把缺失值替换为固定值，固定值可以是字段的平均值、中程数值（最大值和最小值的中间值），以及其他指定的常量

  - 随机：把缺失值替换为该变量对应正态分布活均均匀分布产生的随机值

  - 表达式：把缺失值替换为用户指定表达式的值

  - 算法：选择算法进行插补，SPSS Modeler 将为每个变量构建一个单的C&RT模型，对缺失值进行预测插补

  

# 8：常用统计校验分析

## 8.1 两个联系性变量的关系分析-相关分析

### 8.1.1 相关分析

#### 8.1.1.1 相关分析简介

皮尔逊相关系数，主要用于衡量变量间的线性关系，即一个变量发生改变时，的另一个变量随之发生相关线性变动的关系，皮尔逊相关参数r的计算公式如下
$$
r=\frac{\sum_{i=1}^{n}{(x_i-\overline{x})(y_i-\overline{y})}}{\sqrt{\sum_{i=1}^{n}(x_i-\overline{x})^2\sum_{i=1}^{n}(y_i-\overline{y})^2}}
$$
相关稀释r的取值介于-1到1之间。当r>0时，表示两个变量线性正相关，当r<0时，表示两个变量线性负相关。r的绝对值大小反映了相关程度的强弱，强弱关系如下


| 相关系数            | 相关关系的强度 |
| ------------------- | -------------- |
| 0<=\|r\|<=0.333     | 弱             |
| 0.333<=\|r\|<=0.666 | 中             |
| 0.666<=\|r\|<=1     | 强             |

此外，只通过相关系数说明两个变量存在相关关系是不够的，由于存在抽样误差的影响，还必须对两个变量之间是否存在相关关系进行进一步的检验。检验步骤如下所示

- 提出原假设

  - 零假设H0：两个变量之间不存在线性关系
  - 备设假设H1：两个变量之间存在线性关系
  - 显著水平a=0.05

- 计算检验统计量

  皮尔逊相关系统使用t检验，检验统计量计算如下：
  $$
  t=\frac{\sqrt{n-2r}}{\sqrt{1-r^2}}
  $$

- 计算给定显著水平的临界值或p值，做出推断

  显著水平a=0.05，当p值小于0.05时，可以拒绝原假设，接受备设假设。

#### 8.1.1.2 参数设置说明

  ![image-20230110141820041](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110141820041.png)

  - 设置

    - 检查：需要进行汇总的字段

    - Statistics：选择需要计算的汇总统计量，包括计数、平均值、合计、最小值、最大值、范围（极差）、标准差、标准平均误差、中位数和众数

    - 相关：选择“检查”框中的变量需要与那些变量计算相关系数

    - 相关设置：

      ![image-20230110142207861](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110142207861.png)

      - 在输出中显示强度标签：根据设置的相关强度定义，在输出中显示相关强弱的标签，标签分为强、中、弱

      - 按重要性（1-p）定义相关强度：实际上把相关系数显著性校验结果作为相关强度的度量。重要性=1-p，该值越接近1，说明两个变量存在相关关系的可能性越大
    
      - 按照绝对值定义强度：该值越解决1，说明相关关系越强


        | 相关系数强度标签 | 相关关系的强度 | 相关系数绝对值      |
        | ---------------- | -------------- | ------------------- |
        | 弱               | 0<=1-p<=0.9    | 0<=\|r\|<=0.333     |
        | 中               | 0.9<1-p<=0.95  | 0.333<=\|r\|<=0.666 |
        | 强               | 0.95<1-p<=1    | 0.666<=\|r\|<=1     |

  - 输出

  - 注解

  

## 8.2 两个分类型变量的关系分析-卡方检验

### 8.2.1 列连表与卡方校验

#### 8.2.1.1 卡方校验说明

列连表是一种用于分析两个活更多分类变量的行列交叉表，在列连表的行或列中最少包括一个分类变量，而行和列的交叉单元格内一般用于统计对应的频数，当然也可以进行各种汇总计算，包括求和、平均值、标准差等

在列联表分析中，卡方校验的思想是考察列联表总观察频数和理论频数的差异，当观察频数与理论频数一致的似乎还，卡方统计量为0；当观察频数与理论频数较大时，卡方统计量也更大。具体检验步骤如下

1. 提出原假设

   - 零假设H0：两个变量（行变量与列变量）之间是相互独立的
   - 备设假设H1：两个变量之间并不相互独立
   - 显著水平a=0.05

2. 计算校验统计量

   列联表分析中使用的卡方校验。假定一个r*c规则的列联表，一共k(k=r*c)个单元格，其中第i行第j列单元格观察频数为f_ij，对应的理论频数为Eij，则有卡方统计量如下：
   $$
   x^2=\frac{\sum_{i=1}^{r}\sum_{i=1}^{c}{(f_{ij}-E_{ij})^2}}{E_{ij}}
   $$

   其中，观察频数即为单元格中的期望频数。假定两个变量（行变量与列变量）之间是相互独立的，因此某个单元格中的期望频数Eij=P(r=i)*P(c=j)*n

3. 计算给定显著水平下的临界值或p值，做出推断

   显著水平a=0.05，当x^2>x^2((r-1)*(c-1))（其中(r-1)**(c-1)为x^2的自由度）或对应的p值小于0.05时，可以拒绝原假设，接受备设假设

#### 8.2.1.2 参数设置说明

   ![image-20230110154316089](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110154316089.png)

   - 字段：用于指定列联表中的行列变量
   
     - 选定：手动指定列联表中行和列的变量
  - 所有标志（true值）：把数据文件中所有标志字段都纳入行和列，每个单元格将统计其对应的两个标志量均取值为“真”时的数量。
    
- 所有数值（所有数值）：把数据文件中过的所有数值字段都纳入行和列，每个单元格将统计其对应的两个数值型变量的交叉乘积的总和
  
   - 包含缺失值：将把变量中的缺失值作为一个单变量水平进行统计

   - 单元格内容：选择列联表中每个单元格的统计分析内容
   
  - 交叉列表：对列联表中的交叉变量进行频数统计，特别地，也能通过"外观"选项卡输出更多的汇总统计内容
  
- 函数：指定第三个字段作为交叠字段进行统计。
  
   - 外观

     ![image-20230110155518120](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110155518120.png)
   
     - 行和列：选择是否对行和列进行排序，包括有“不排序”、“升序”、“降序”
  - 交叠字段：用于突出显示列联表中的极值。选择“突出显示前几个值”将使用红色显示，选择“突出显示后几个值”将使用绿色显示
    
     - 交叉列表单元格内容：用于指定列联表单元格中更多汇总统计量。其中“期望值”是卡方校验的期望频数，“残差”是观察频数和期望频数的差值

   

## 8.3  连续型变量与分类型变量间的关系分析-t检验及卡方检验

### 8.3.1 两组独立样本均值比较

两组独立样本均值比较值是从两个独立总体分别抽取样本进行比较，两组样本没有相互影响，可以使用两组独立样本t校验，在SPSS Modeler 中，两组独立样本的均值比较实际上是使用单因素方差分析，但可以证明当组别只有两个水平时，单因素方差分析等价于两组独立样本t校验，具体校验步骤如下：

- 提出原假设

  - 零假设H0：两个独立样本之间，并无显著差异，u1=u2
  - 备设假设H1：两个独立样本之间，有显著差异，u1!=u2
  - 同时设定显著水平a=0.05

- 计算检验统计量

  使用独立样本t校验，检验统计量计算如下：

  $$
  t=\frac{\overline{X_1}-\overline{X_2}}{\sqrt{(S_p^2(\frac{1}{n_1}+\frac{1}{n_2})}}
  $$
  
$$
S_p^2=\frac{S_1^2(n_1-1)+S_2^2(n_2-1)}{n_1+n_2-2}
$$

  		其中，X1以及X2分为对应两组的均值，n1和n2分别为两组样本数量，Sp^2为两组合并方差，S1^2和S2^2分别为两组的方差，n1+n2-2为t校验统计量的自由度

- 计算给定显著水平的临界值或p值，做出推断

  显著水平a=0.05，当p值小于0.05时，可以拒绝原假设，接受备设假设。

### 8.3.2 两组配对样本均值比较

两组配对样本均值比较指的是两个组别之间是一一配对的。可以是一个样本前后状态的比较，



两组独立样本均值比较值是从两个独立总体分别抽取样本进行比较，两组样本没有相互影响，可以使用两组独立样本t校验，在SPSS Modeler 中，两组独立样本的均值比较实际上是使用单因素方差分析，但可以证明当组别只有两个水平时，单因素方差分析等价于两组独立样本t校验，具体校验步骤如下：

- 提出原假设

  - 零假设H0：两个配对样本之间，并无显著差异，u1=u2
  - 备设假设H1：两个配对样本之间，有显著差异，u1!=u2
  - 同时设定显著水平a=0.05

- 计算检验统计量

  使用配对样本t校验，检验统计量计算如下：

  $$
  t=\frac{\overline{d}-0}{\frac{S_d}{\sqrt{n}}}=\frac{\overline{d}}{\frac{S_d}{\sqrt{n}}}(自由度v=n-1)
  $$


  		其中，d为每组配对样本差值的均值，而Sd为每组配对样本差值的表的标准层，n为配对的组数

- 计算给定显著水平的临界值或p值，做出推断

  显著水平a=0.05，当p值小于0.05时，可以拒绝原假设，接受备设假设。

### 8.3.3 方差分析

​	多组样本均值比较指的是两组及两组以上的均值比较。单因素方差分析分析，具体步骤如下

- 提出原假设

  - 零假设H0：多个个样本之间，并无显著差异，u1=u2=....=um
  - 备设假设H1：多个样本之间，有显著差异，ui(i=1...m)不全相等
  - 同时设定显著水平a=0.05

- 计算检验统计量

  在方差分析中，把观察值的总变化分为组间变化和组内变化，有：SST=SSA+SSE

  其中

  - 总平方和
    $$
    SST={\sum_{i=1}^{m}\sum_{j=1}^{n_j}{(x_{ij}-\overline{x})^2}},自由度为n-1
    $$


  - 组间平方和
    $$
    SSA={\sum_{i=1}^{m}{(\overline{x_i}-\overline{x})^2}},自由度为m-1
    $$

  - 组内平方和
    $$
    SSE={\sum_{i=1}^{m}\sum_{j=1}^{n_j}{(x_{ij}-\overline{x_i})^2}},自由度为n-m
    $$

  上式中，n为样本总量，m为研究因数包含的水平个数，xij为第i个水平第j个观测值，ni为第i个水平的样本量，xi为第i个水平的平均值，x为总平均值

  在方差分析中，使用F统计量：
$$
  F=\frac{MSA}{MSE}=\frac{\frac{SSA}{m-1}}{\frac{SSE}{n-m}}
$$

  F统计量服从自由度为(m-1,n-m)的F分布，上式中的MSA为组间均方，MSE为组内均方，平方和除以自由度得出均方 

- 计算给定显著水平的临界值或p值，做出推断

  显著水平a=0.05，当p值小于0.05时，可以拒绝原假设，接受备设假设。

### 8.3.4 参数设置说明

  ![image-20230110172627343](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110172627343.png)

  - 设置
  
    - 比较平均值
    - 在字段的组之间：进行独立组比较，需要指定分组字段（分类型变量）、以及测试字段（连续型变量），一般情况下，当分组字段只有两个水平，应使用独立样本t校验。当分组字段超过两个水平以上时，将使用单因素方差分析，在SPSS Modeler 中，将统一使用方差分析。实际上，当组别只有两个水平时，单因素方差分析等价于两组独立样本t校验
      - 在字段对之间：进行配对组比较。需要指定字段1（连续型变量）和字段2（连续型变量）作为配对的两组样本。在字段对之家，可以选择多组字段对进行比较。特别的，在进行字段对比间比较的同时，“平均值”节点也将输出字段对直接的相关分析结果

  - 选项

    ![image-20230110173608035](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110173608035.png)

    

  - 输出

  - 注解

  ​	

# 9：回归分析

回归分析是一种研究自变量x与因变量y之间数量关系的统计分析方法。通过构建回归模型，能够量化描述自变量x与因变量y的关系，同时也可以实现对因变量y的预测。回归分析是一类统称的分析技术，具体包括线性回归、Logistic回归、多项式回归、岭回归等技术

### 9.1 一元线性回归分析

#### 9.1.1 一元线性回归分析简介

一元线性回归又称简单线性回归，是线性回归中最简单的形式。一元线性回归方程中只包括一个自变量x，有如下形式
$$
y=β_0+β_1x+ε
$$
可以使用一元线性回归来研究一个自变量与一个因变量的线性关系。

使用一元线性回归分析，一般分为5个步骤

- 分析变量关系，构建回归分析

  需要根据业务需求以及分析目标确定需要分析的自变量以及因变量，并且为了进一步考察自变量与因变量是否存在线性关系，可以绘制对应的散点图以及进行相关分析，从而确定回归模型形式

  一旦从形式上确认使用线性回归模型，就可以借助一元线性回归模型对自变量及因变量的关系进行描述，回归模型形式如下：
  $$
  y=β_0+β_1x+ε
  $$
  y是因变量，x是自变量，β0是常数项，β1是回归系数，ε是随机误差。在这里，因变量y的变化分为两部分：一部分是由自变量x所引起的β0+β1x，另一部分是由暂时不能解释的随机因素引起的ε，在公式中β0，β1都是未知参数。而我们就是要利用已知的样本数据(x1,y1),(x2,y2)....,(xn,yn)对未知参数β0，β1进行估计。

- 估计模型系数，求解回归模型

  确定了回归模型形式后接下来，就是利用样本数据进行参数估计。一般可以借助最小二乘法来求解参数β的估计值。

  要对方程的位置参数进行估计，一个直观的想法就是求解得到的回归直线能够尽可能贴近现有的观察数据。也就是残差尽可能的小。

- 检验模型系数，确认系数有效

  尽管已经完成对回归参数的估计，但是事实上模型是否有效还需要进一步检验。这是因为参数估计只是解决了在给定因变量及自变量的前提下，求得使残差平方和最小的回归方程，但是自变量本身是否对因变量有影响作用，还需要接触假设检验的方法进行检验。在此处，使用t检验

  1. 提出原假设
     - 零假设H0：因变量y与自变量x的线性关系不显著，β1=0
     - 备设假设H1：因变量y与自变量x的有显著的线性关系，β1!=0
     - 同时设定显著水平a=0.05
  2. 计算检验统计量
  3. 计算给定显著水平下的临界值或p值，做出推断

- 拟合优度检验，模型解释能力

  通过系数检验已经说明了自变量对因变量存在一定的线性相关关系，但是这个解释能力能否解释因变量的变化，还需要对其进行拟合优度检验，一般可以用决定系数来进行相应的度量

- 借助回归模型，进行分析预测

#### 9.1.2 参数设置说明

  ![image-20230110213422253](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110213422253.png)

  - 字段
    
    - 使用预定义角色：将使用上游节点的字段信息作为模型角色定义
  - 使用定制字段分配：忽略上游节点的字段信息设，手动指定字段的角色
    
- 使用权重字段：与“频率”角色功能类型，差别在于频率字段要求值为正整数，权重字段仅要求是正数即可
  
  - 模型

    ![image-20230110213737077](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110213737077.png)
  
    - 使用分区数据：使用训练集进行模型训练、测试集进行模型评估
    - 为每个分割构建模型：
    - 方法：指定构建线性回归模型的方法
      - 进入法：把所有的自变量纳入模型而不做任何的筛选
      - 步进法：将自变量逐个引入模型并进行统计显著性检验，直至再也没有不显著的自变量从回归模型中剔除为止；
      - 前进法：一个逐步增加变量的过程，它根据检验准则，每一步增加一个当前未选入变量中最显著的变量，直到没有新的变量别引入为止
    - 后退法：她是一个逐步减少变量的过程，利用所有自变量建立全模型，再根据检验标准逐个剔除无效变量。
    - 在等式中包含常量：选择是否在构建的回归方程中包含常量β0

  - 专家
  
    ![image-20230110214307364](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230110214307364.png)
    - 模式：
      - 简单：
      - 专家：针对模型参数进行调整
  - 缺失值：默认节点仅使用完整记录构建回归模型，取消选项后，将会使用缺失值记录纳入蘑菇小构建
  
- 异常值容差：容忍度阈值设置。容忍度是衡量模型多重共线性的指标之一，回归节点默认容忍度为0.0001，即当某变量的容忍度小于此值时，将不会纳入模型
  
  - 分析
  
  - 注解

### 9.2 多元线性回归分析

多线线性回归的步骤一般如下

1. 分析变量关系，构建回归模型

   对于多元线性回归，确定好对应的因变量和自变量后，一般有如下形式
   $$
   y=β_0+β_1x_1+β_2x_2+...β_mx_m
   $$

2. 估计模型系数，求解回归模型

3. 检查整体模型，确认是否显著

   在一元线性回归中，使用t检验来验证自变量与因变量的关系，这是因为自变量就代表了整体方程对因变量的影响，在多元回归分析中，如果要确认回归方程整体的显著性，就需要借助其他方法

   实际上，要验证研究回归方程是否对因变量y产生影响，只需要验证命题“是否所有的回归系数”βi都等于0即可

   根据平方和分解式，可以把因变量的波动情况（SST）分解为两部分：能够有模型解释的部分和不能被模型结束的部分

   具体步骤如下：

   1. 提出原假设

      - 零假设H0：β1=β2=....=βm=0
      - 备设假设H1：至少存在一个βi显著不为0
      - 同时设定显著水平a=0.05

   2. 计算检验统计量

   3. 计算给定显著水平下的临界值或p值，做出推断

      至少存在一个βi显著不为0，可以认为回归方程整体是显著的

4. 检验模型系数，看看系数相关

   

5. 拟合优度检验，模型解释能力

6. 借助回归模型，进行分析预测

### 9.3 逐步线性回归分析

# 10：Logistic 回归分析

### 10.1 Logistic 回归分析理论概要

由于分类型变量并不符合传统回归分析的要求，因为是无非直接把数据代入变量进行学习的，虽然无非对预测的标记进行建模，但是可以改用事件的发生概率作为模板。

使用概率作为目标进行预测时，需要注意

1. 一般线性函数的取值范围在-∞到∞之间，而概率的取值范围则是在0到1之间。在线性模型的情况下，模型本身并不能保证求得的所有因变量估计值都在[0,1]之中，因而用户需要选择合适的转换，使得取值范围一致。
2. 概率的变量通常并不遵循线性变化，实际上概率往往和输入变量间存在非线性关系

### 10.2 Logistic 回归中的检验

- 方程的显著性校验

  与线性回归类型，尽管通过极大似然估计方法完成对参数的估计，但是事实上模型是否有效还需要进行进一步验证，这是因为参数估计只是解释了在给定因变量及自变量的前提下，求得极大似然函数得到最大的Logistic回归方程。因此，还需要通过进一步的检验以判断该方程是否相比于原始模型（不含任何参数的空模型）的拟合程度有所增强。

  由极大似然估计可以得知，似然函数越大，说明方程的拟合程度效果越好

  具体步骤如下：

  - 提出原假设

    - 零假设H0：β1=β2=....=βm=0
    - 备设假设H1：至少存在一个βi显著不为0
    - 同时设定显著水平a=0.05

  - 计算检验统计量

  - 计算给定显著水平下的临界值或p值，做出推断

    当G>x_a^2时，可以拒绝原假设，认为方程中事少存在一个自变量的回归系数等于0

- 系数显著性校验

  与线性回归分析类似，借助x^2校验，只能说明方程显著，但是这并不意味着对所有的自变量都对因变量有显著影响，在Logistic中，常用的检验方式包含似然比检验，Wald校验和比分校验（Score Test）

  - 似然比检验

    - 与方程的显著性检验类型，似然函数越大，说明方程的拟合效果越好，因此同样能用改思想进行系数的校验

  - Wald校验

    - Wald校验的计算要比似然比校验更加简单，相对于似然比校验从总模型整体拟合情况出发，wald检验只是考察系数本身是否等于0

  - 比分校验

    - 比分检验以引入变量x_k之前的模型为基础，保留引入前的参数估计值并把x_k的参数估计值设置为0，计算器对数似然函数的一阶偏导以及方差的协方差矩阵，其乘积即为比分统计量

    由于似然比校验与方程的推到相关联嘛，并且其能综合考察某自变量引入对方差整体拟合程度的影响，因此似然比检验最为常用。一般来说，比分校验与似然比校验的结果相差不大，wlad值考虑单个变量的影响，其结果偏向保守。并且可靠性一般要低于上述两种方法

- 拟合优度校验

  与线性回归类似，模型和系数通过显著性校验只能说明因变量与自变量间存在统计上的关系，并不能说明方程对因变量有足够好的解释能力。因此为了说明自变量对因变量的解释能力，还需要进行拟合优度检验，在Logistic回归中，常用的拟合优度校验方法包括Cox&Snell R^2系数，Nagelkerke R^2系数、Hosmer-Lemeshow 检验以及混淆矩阵

  - Cox&Snell R^2系数

  - Nagelkerke R^2系数

  - Hosmer-Lemeshow 检验

  - 混淆矩阵

### 10.3 参数设置说明

  ![image-20230111085013146](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111085013146.png)

  - 字段

  - 模型

    - 模型名称

      - 自动
      - 定制

    - 使用分区数据：将使用训练集进行模型训练，测试集进行模型评估

    - 为每个分割构建模型：如果类型节点把某个字段角色设置为“拆分”，定义了分割字段，则模型将为该字段下的每个分割单独构建一个模型。

    - 过程：根据因变量类别数指定用于Logistic的模型形式。当因变量是两水平分类变量时，应当选择“二项式”。当原因变量是多水平分类变量时，应当选择多项式。

      - 多项式

        - 方法
          - **进入法**——强制将所选择的自变量纳入回归模型中；
          - **步进法**——将自变量逐个引入模型并进行统计显著性检验，直至再也没有不显著的自变量从回归模型中剔除为止；
          - **后退步进发**——根据设定条件，直接剔除一部分自变量；
          - **后退法**——根据设定条件，每次剔除一个自变量直至不能剔除；删除后不再检查该变量能否再进入模型
          - **前进法**——根据设定条件，每次纳入一个自变量直至无法继续纳入。添加后不会从模型中删除任何变量
          - 
        - 目标的基准类别：因为多项式含有多个类别，所以可以指定任一个水平作为基准类别
        - 模型类型
          - 主效应：只选择输入变量作为自变量作为自变量而不考虑变量间的交互效应
          - 全析因：包括所有输入变量的主效应及其所有交互效果组合
          - 定制：手动指定需要加入模型中的效应

      - 二项式

        - 方法

          - **进入法**——强制将所选择的自变量纳入回归模型中；
          - **向前步进法**——将自变量逐个引入模型并进行统计显著性检验，直至再也没有不显著的自变量从回归模型中剔除为止；
          - **后退步进法**——根据设定条件，每次剔除一个自变量直至不能剔除；

        - 分类输入

          在回归模型中，系数表示自变量一个单位的变化带来因变量的平均变化的量，这对于连续型的自变量没有任何问题，但是当自变量中含有分类型变量时，则可能带来问题。这是因为分类型自变量本身不存在 连续变量的大小的次序关系，即对于定序的分类变量来说，不同的类别也并不是等距离的，直接把分来变量输入模型将带来较大的问题。因此需要对分类自变量设置哑变量

          对于含有n个水平的分类型自变量来说，需要设置n-1个哑变量

          ![image-20230111090824392](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111090824392.png)

          - 字段名称：那些变量需要进一步设置哑变量
          - 对比：设置哑变量的方式
            - 指示器：将计算所有水平相比于基准类别相比于的估计值，可以在基准类别中设计第一个或最后一个作为该变量的参考水平
            - 简单：与指示器方法类似，只是在常数项中有所差异。反映的是基准类别对因变量的影响，而这里反映的是所有水平对因变量平均影响
            - Helmert：变量水平与后面水平的平均值进行比较，
            - 差值：变量水平与前面水平的平均值进行比较，即水平2与水平1进行标记，水平3与水平2及水平1的平均值进行比较
            - 重复：每个类别与它的一个类型进行比较，第一个类别除外
            - 多项式：仅适用于数值型的分类变量，一次选择变量的一个次方程进行比较
            - 偏差：除基准类别外，每个类别与总体平均水平作为比较
          - 基准类别：设置基准类型，其他差值、Helmert、重复、多项式 不适用与此选项

    - 在等式中包含常量

  - 专家

    ![image-20230111093245382](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111093245382.png)

    - 模式
      - 简单
      - 专家
    - 刻度
    - 追加所有概率：将在模型结果中输出所有预测类别的概率，其中二项式模型将保持选中此项
    - 异常值容差：与“回归”节点类似，用于容忍度阈值设置
    - 收敛：用于设定参数计算的收敛标准
    - 输出：输出更多的统计量
      - 显示：选择显示每个步骤的结果还是只显示最终步骤的结果
      - 迭代历史记录：显示从起始阶段、每次参数估计的迭代历史记录
      - 参数估计：方程的系数估计、系数检验结果以及e^β等
      - 分类图：显示混淆矩阵结果
      - exp(B)的CI(%)：e^β的置信区间
      - 残差诊断：显示对应的残差诊断分析结果
      - 分类分解值：对于二项模型来说，默认分解值为0.5，即预测概率大于0.5时，预测变量将被标记为T，预测概率小于0.5，预测变量被标记为F
      - Hosmer-Lemeshow 拟合度：输出Hosmer-Lemeshow 检验结果
    - 步进：选择步进法的校验标准

  - 分析

  - 注解

![image-20230111095147477](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111095147477.png)

# 11：RFM 分析

RMF分析在零售行业引用较为广泛。从应用的角度看，在针对客户洞察分析中，如果客户的属性比较缺乏，难以构建客户360读视图。只要有订单数据，就可以简单应用RMF模型，对客户的购买行为进行特征分析。R(Recency)表示客户购买的时间距离当前时间（或某一时间点）有多久，F（Frequency）表示客户在该时间内购买的次数，M（Monetary）表示客户在该时间内够么的金额，RFM模型是衡量客户价值和客户创利能力的重要工具合手段。该模型通过一个客户的近期购买行为、购买的总体频率以及花了多少钱这3项指标来描述该客户价值状况，RFM强调客户的行为来区分客户。

## 11.1 参数设置说明

RFM 汇总节点

![image-20230111143107778](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111143107778.png)

![image-20230111141018124](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111141018124.png)



- 设置
  - 计算相对于此日期的近期：因为原始数据中有日期这一信息，要计算最近一次购买的日期到当前日期相隔的天数
    - 固定日期
    - 今天的日期
  - 表示连续：如果数据进行了预先排序，以便所有具有同一个标识的记录一起出现在数据流中，那么选择此选项可以加快处理速度
  - 标识：要对那个字段进行RMF分析
  - 日期：用来计算近因的日期字段
  - 值：用户计算客户交易的总金额
  - 新的字段名拓展：默认会生成3个新字段，分别描述上次消费时间、频率、货币。如果需要对这3个字段前后增加字段描述，可以在这个设置
  - 丢弃具有以下值的记录：某些场景中，如果金额太低，不考虑作为计算RFM的数据，可以在这里设置
  - 只包含最近交易：如果原始数据周期比较长，而用户只想计算最近一段时间的数据，可以在这里设置
    - 以下日期后的交易日期：指定交易日期后的数据
    - 最近的交易：相对当前时间的固定周期时间（周期为 日、周、月、年）
  - 保存第二个最近交易的日期：会生成一个新的列R2，计算第二个最近交易的日期值当前日期或设置的固定日期的间隔天数
  - 保存第三个最近交易的日期：会生成一个新的列R3，计算第三个最近交易的日期值当前日期或设置的固定日期的间隔天数
- 注解

RMF汇总节点

![image-20230111143209971](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111143209971.png)

![image-20230111142700026](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111142700026.png)



- 设置：

  - 上次消费时间：
  - 频率：
  - 货币：
  - 上次消费时间：
  - 频率
  - 货币
  - 结：指定如何区分分级相同的评分
    - 添加到下一个：将结值上移至下一个分级
    - 处于最新状态：将值 保留在当前（较低）分级中，此方法可以减少创建的分级总数
  - 分级阈值：指定在执行节点时是始终重新计算RFM分值和分级分配，还是仅在需要时进行计算（如添加了新数据时）
    - 始终再计算
    - 如果可用，从“分级值”选项卡读取
    - 将离群值添加到最终分级：可将离群值分别添加至最高或最低级别中，否则将空值分配给这些记录

- 分级值：

  ​	![image-20230111142748864](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111142748864.png)

  

- 注解：

  ​	![image-20230111152109917](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111152109917.png)



# 12：决策树分析

### 12.1 决策树概述

决策树算法是一种有监督的机器学习算法，作为有指导学习算法，它要求有输入变量及目标变量。一般来说，决策树常用于解决分类问题。但部分决策树算法也能解决回归问题

#### 12.1.1 决策树的理解

决策树算法就是根据训练数据集，通过一系列测试问题，从而完成对输入分类目标进行划分。从图形展示上来看，决策树是由一个根节点、若干个内部节点以及若干个叶子节点组成，其中，根节点和内部节点分别代表一个测试划分条件，而叶子节点则代表最终的划分输出结果

1. 根节点

   决策树的起始根部，代表了决策树的第一个测试条件。一颗决策树有且仅有一个根节点，根节点没有入边，拥有零条或以上的出边

2. 内部节点

   决策树的树干，与根节点一样，代表了一种测试条件。中间节点有一条入边，拥有两条或以上的出边

3. 叶子节点

   决策树的终端，决策树的最终划分输出结果。叶子节点只有一条入边而没有出边

决策树算法拥有其他算法锁不能比拟的只管，只有从根节点出发，并到任意一个叶子节点，都将形成一条判断规则，值得注意的是，通过决策树所形成的规则应当是互斥完备的，即对应任意一个样本数据，有且只有一条规则与其一一对应并输出最终的分析结果。

#### 12.1.2 决策树的生长

决策树的生产，其实就是一个个节点（测试划分条件）的生成过程。前面提到，通过测试条件，把训练数据划分为不同的集合，因此在决策树生长的阶段，最主要回答两个问题：

1. 选择什么样的测试条件进行分裂生长
2. 什么时候可以结束分裂生长

就分类模板而已，希望原始数据集在通过一个个测试条件的划分后，得到的数据子集能够显得更加的“纯”，也就是划分后的任一子集都尽可能属于同一个类别。

为了能够尽可能划分完全，用户应该在每次划分过程中选择可以令子集纯度跟高的划分条件，随着训练数据集不断地被划分，子集的纯度也应该越来越高。直到划分结束

划分结束条件如下：

- 子集中所有的样本都属于同一类别：不需要再进行划分
- 子集中所有的样本属性都一样：继续划分也不能改善结果
- ![决策树流程示意图](https://img-blog.csdnimg.cn/5c9ef7847f604e2b9d20645c437f942a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zue5LiA5bm7,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

从决策树生长过程流程图可以发现，决策树生长的重点在于其中“纯度”的度量，即选择最优特征过程，一般，不同的决策树算法将使用不同“纯度”计算公式

#### 12.1.3 决策树的剪枝

按照决策树的生长过程及生长终止条件，得到的决策树是“详尽而精确”的。当用户的数据集中不存在两个属性相同而标记不同的样本时，总能通过不断添加测试条件在训练数据集上得到100%的准确率

事实上，这课“精尽而精确”的决策树往往不是用户需要的，这事因为随着决策树的不断生长，带划分子集的样本将越来越少，而根据小样本集所得到的划分特征可能只是符合少数个例而不具备任何的推广性

在决策树算法的初始生长阶段，随着算法对数据的不断拟合（对应数的生长），无论是训练集，还是测试集的预测误差都在急剧减少。但是随着对数据中信息的不断拟合以及信息提取，预测误差的下降开始放缓，而测试集则是在到达某一“低点”后开始反弹缓慢上升，事实上，这个时候可能已经出现了“过拟合”的问题，为了解决“过拟合”问题，用户可以借助剪枝技术。一般而言，决策树的剪枝可以分为预剪枝及后剪枝。预剪枝技术主要通过增加生长的限制条件来语法过拟合的出现，而后剪枝技术则是在决策树生成充分后，再通过一定的标准对决策树的某些分支进行修剪，而达到防止过拟合的目的。



### 12.2 C5.0 算法

#### 12.2.1 C5.0 算法的决策树生长

决策树的生长的核心在于纯度的衡量方式，而ID3算法则是利用熵来衡量样本子集的纯度。设样本集合D中含m类样本，对应每类样本比例分别为Pk(k=1,2...m)，则集合D的信息熵被定义为
$$
Ent(D)={\sum_{i=1}^{m}{p_klog_2\frac{1}{p_k}}}=-{\sum_{i=1}^{m}{p_klog_2{p_k}}}
$$

上式在计算中，有0log_2 0=0；

前面说到，信息熵是用来描述信息“混乱”程度的，所以*Ent(D)*越大，可以认为集合*D*的纯度越低；所以*Ent(D)*越小，集合*D*的纯度越高。另外，计算得知，当集合*D*中存在pk=1时，*Ent(D)*=0，信息熵取得最小值，纯度达到最高；相反，当集合*D*中的m中情况都是等可能发生的情况下，即p1=p2=....pm=1/m时，信息熵取得最大值，集合D的不确定性最大

#### 12.2.2 C5.0 算法的决策树剪枝

#### 12.2.3 代价敏感学习
#### 12.2.4 参数设置说明

![image-20230111164154220](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111164154220.png)

- 设置（与回归分析中的设置一致）

  - 使用预定义角色
  - 使用指定字段分配
  - 目标
  - 输入
  - 分区
  - 分割
  - 使用权重字段

- 模型

  ![image-20230111164327700](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111164327700.png)

  - 模型名称
  - 使用分区数据：使用训练集进行模型训练，测试集进行模型评估
  - 为每个分区构建模型：如果在类型节点中把某个字段设置为拆分（分割字段），则模型将为该字段下个没一个分割单个构建一个模型。
  - 输出类型：设定结果的生成方式
    - 决策树：使用C5.0 模型进行构建，输出树状结果
    - 规则集：利用PRISM的生成规则集算法进行模型构建，输出“规则分类结果”
  - 组符号：尝试对分组变量的相似类别进行合并
  - 使用boosting：节点将使用模型组装技术Boosting来生成多颗决策树，并通过组合投票的方式得出最后结果，一般情况下，该选项将提高模型的准确率
  - 交叉验证：将使用校验验证的方式对模型进行评估
  - 模式：用于模型的构建
    - 简单：
      - 支持：选择决策树生成模式，包括准确性和普遍性
        - 准确性：将生成一个更详尽而精确的模型，不过可能带来过拟合的问题
        - 普遍性：将生成一个更精简更具普遍性的模型，不过该模型在训练集的精度可能会适度下降
      - 预期噪声（%）：指定训练集中噪声样本的数量
    - 专家
      - 修剪严重性：具体指定决策树的修剪程度，默认为75%，该值越大，得到的决策树就越精简
      - 每个子分支的最小记录数：预剪枝策略，只有当子树的记录数量大于此值时，才会发生分裂。此项有助于防止过拟合的问题的出现
      - 使用全局修剪：C5.0 的剪枝分为两个阶段，即局部剪枝和全局剪枝。节点默认执行全局剪枝
      - 辨别属性：节点将在使用算法前先进行自变量的有效评估，若某变量在建模前发现与因变量关系不大，节点将剔除该字段进行建模。

- 成本：主要用于设定误差成本代价

  ![image-20230111170428182](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111170428182.png)

- 分析

  ![image-20230111170629596](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111170629596.png)

  

- 注解

![image-20230111171340809](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111171340809.png)



### 12.3 CART 算法

CART（分类与回归树），与C5.0算法思路有所类似，主要区别如下

1. 与C5.0算法只能处理分类型目标变量生成分类树不同，CART既能处理分类型的目标变量生成分类树，还能处理连续型的模板变量生成回归树
2. 在决策树的生长阶段，CART算法分别采用基尼系数（分类树）以及方差（回归树）作为树生长的衡量指标
3. 修剪方法不同，C5.0算法基于悲观误差估计进行剪枝，而CART算法是根据最小代码复杂度剪枝
4. CART决策树是一种二叉树结构，无论变量的水平有多少种，最后只会生成两个分支，C5.0决策树能生成多叉树

#### 12.3.1 CART 算法的决策树生长

##### 12.3.1.1 分类树

C5.0算法中，使用熵节点作为纯度的衡量，而在CART算法中，使用基尼指数来进行节点纯度的衡量

##### 12.3.1.2 回归树

与分类树不同，信息熵或者基尼系数不再适用于连续型的目标变量。在分类树中，使用类别的众数作为叶节点的最终输出，而在回归树中则使用节点t的输出均值y(t)作为最终输出

#### 12.3.2 CART 算法的决策树剪枝

​	与C5.0算法类似，CART算法中将综合使用预剪枝及后剪枝的混合策略

##### 12.3.2.1 预剪枝策略

CART的预剪枝策略相比于C5.0要更加丰富，主要包括2个方面

1. 指定决策树节点样本数量的下限

   在树生成的过程中，一旦节点中的样本数量低于指定下限，将停止该分支的生成。在CART算法中，节点样本下限的设定方式有：

   - 指定父节点的下限（绝对值或样本比例）
   - 指定子分支节点的下限（绝对值或样本比例）

2. 指定决策树的最大生成深度

   在决策树生成的过程中，当达到指定深度后，决策树即停止生长。假如指定了决策树的最大深度为5，则在决策树生成的过程中最多只能分支5层，即算上根节点，整个决策树只有6层

##### 12.3.2.2 后剪枝策略

​	与C5.0算法一样，为了获得相对合适的决策树，依然需要对其进行剪枝，实际上，在训练集中模型的精度越高，他就越复杂。越复杂的模型，泛化能力则越差。因此为了能够获得一个模型精度复杂度都相对合适的模型，CART采用一种名为最小代价复杂度剪枝法，一般可以使用预测误差或者基尼系数作为预测误差（损失），叶子点数目作为复杂度。

#### 12.3.3 先验概率

### 12.3.4 参数设置说明

![image-20230111222158166](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111222158166.png)



- 字段

- 构建选择

  1. 目标

     - 希望做什么：
       - 构建新模型：每次运行模型节点，将生成一个全新的模型
       - 继续训练现有模型：针对模型节点最后一次生成的模型进行继续训练。该功能在有新纪录加入的时候将显得特别有用
     - 主要目标是什么：
       - 构建单个树：创建标准的CART决策树模型
         - 生成模型：按照标准算法，SPSS Modeler 自动创建模型
         - 启动交叉会话：SPSS Modeler 将弹出模型树模型构建器，使得用户能够按照需要完全自定义生成模型。用户可以在构建器中按照需要逐层甚至指定使用某个变量生成模型
         - 使用树指令：实际上是交互会话的指令版本，用户可以保存在交互会话中的指令，在此处通过指令构建模型
       - 增强模型的准确度（Boosting）：使用集成算法Boosting构建多个数模型，此方法能够增强模型的准确性，但也需要更多的模型训练时间
       - 增强模型的稳定性（Bagging）：使用集成算法Bagging构建多个模型，此方法能够增强稳定性并避免模型过度拟合，但也需要更多的模型训练时间
       - 为大型数据集创建模型（需要Server）：使用超大型数据集时，请选择此选项，否则使用上述标准模型时可能出现警告及报错，该选项将连接至SPSS Modeler Server 中，并将超大型数据集划分为更小的数据集，从而创建模型

  2. 基本

     ![image-20230111224300051](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111224300051.png)

     - 最大树深度
     - 修剪
       - 修剪树以防止过度拟合：对生成的决策树进行后剪枝操作，以防止过拟合。
       - 设置最大风险差（标准误差）：CART默认选择在验证集中有最低预测误差的决策树。可以增加风险误差
       - 最大代用项：CART 算法中处理缺失值的方法。在决策树长分支的过程中，CART会识别与被用于进行分割变量的最相似变量，这些最相似的变量就是代用项。当对某个记录进行分类时，假如记录在某个变量上存在缺失，CART将使用一级代用项的值作为代替。如果一级代用项人存在缺失值，就将使用二级代用项代替，以此类推，直到最大代用项为止

  3. 终止规则

     ![image-20230111225123467](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111225123467.png)

     终止规则用于设定什么时候停止树分支进行分裂。在树生成的过程中，一旦节点中的样本数量低于指定下限，就将停止该分支的生成。C&R树节点中提供了使用百分比和使用绝对值两种方式

  4. 成本和先验

     ![image-20230111230529766](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111230529766.png)

     - 使用错误分类成本：设定误差成本代价
     - 先验
       - 基于训练数据：默认数据，将根据训练数据进行计算
       - 对于所有类型都相等：强行令所有类型的先验概率取相同的值
       - 定制：手动指定每个类别的先验概率，需要保证所有的先验概率的总和等于1
         - 标准化：设置每个类别的先验概率不相等
         - 均衡：所有类别的先验概率均相等
     - 使用错误分类成本调整先验：如果已经定义了错误分类成本，那么算法将使用误分类成本调整先验概率，从而影响生长过程

  5. 整体

     ![image-20230111231156782](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111231156782.png)

  6. 高级

     ![image-20230111231221641](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111231221641.png)

     - 最小杂质改变：*ΔGini*的下限阈值，父节点纯度与子节点纯度差值，只有*ΔGini*大于此阈值，父节点才会产生分裂
     - 分类目标的杂质测量：定义节点的纯度测量方式
       - Gini：基尼系数
       - 两分法：即Tower策略，对于多分类的自变量，由于C&RT算法只能形成二叉树，因此需要对变量水平进行合并，在Tower策略中，节点的纯度衡量依然使用基尼系数，但是分裂变量不再使用基尼指数下降最快的原则，而是使用最后形成左右节点的分布差异足够大
       - 有序：针对定序型变量，对应分类的自变量，由于C&RT算法只能生成二叉树，因此需要对变量水平进行合并。该策略限制了只有相邻的变量才能进行合并，对于名义型分类变量，将会选用二分法
     - 过度拟合防止集合：从训练集中抽取独立的样本作为验证集，用于后剪枝的检验
     - 复制结果：由于验证集的抽取是使用随机抽样方式。通过设置随机种子，可以保证重现结果

- 模型选择

- 注释

  ![image-20230111233136491](http://cdn.luluwanlong.cn/spss-modeler-analysis-image-20230111233136491.png)


